{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOr4sAxbS2y/IQXlVS/Y6y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varthini-30/google-collab/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhp5fTBbjcJN",
        "outputId": "f4c2b8e4-20d1-49a0-cdb2-8ad383950fe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1783\n",
            "{'the': 1, 'and': 2, 'of': 3, 'i': 4, 'to': 5, 'a': 6, 'in': 7, 'was': 8, 'it': 9, 'as': 10, 'that': 11, 'my': 12, 'with': 13, 'he': 14, 'on': 15, 'had': 16, 'for': 17, 'which': 18, 'not': 19, 'me': 20, 'but': 21, 'were': 22, 'we': 23, 'his': 24, 'at': 25, 'they': 26, 'you': 27, 'all': 28, 'could': 29, 'there': 30, 'so': 31, 'seemed': 32, 'from': 33, 'is': 34, 'by': 35, 'them': 36, 'have': 37, 'this': 38, 'then': 39, 'driver': 40, 'very': 41, 'be': 42, 'through': 43, 'us': 44, 'some': 45, 'when': 46, 'or': 47, 'time': 48, 'over': 49, 'what': 50, 'horses': 51, 'an': 52, 'up': 53, 'said': 54, 'into': 55, 'see': 56, 'great': 57, 'out': 58, 'one': 59, 'do': 60, 'here': 61, 'know': 62, 'are': 63, 'must': 64, 'again': 65, 'though': 66, 'been': 67, 'before': 68, 'white': 69, 'down': 70, 'him': 71, 'our': 72, 'count': 73, 'door': 74, 'side': 75, 'now': 76, 'may': 77, 'no': 78, 'long': 79, 'saw': 80, 'old': 81, 'round': 82, 'she': 83, 'did': 84, 'began': 85, 'like': 86, 'will': 87, 'go': 88, 'would': 89, 'way': 90, 'am': 91, 'if': 92, 'looked': 93, 'place': 94, 'got': 95, 'came': 96, 'sort': 97, 'man': 98, 'her': 99, 'your': 100, 'road': 101, 'darkness': 102, 'wolves': 103, 'night': 104, 'light': 105, 'any': 106, 'than': 107, 'went': 108, 'strange': 109, 'come': 110, 'took': 111, 'after': 112, 'along': 113, 'country': 114, 'just': 115, 'own': 116, 'well': 117, 'who': 118, 'their': 119, 'dark': 120, 'back': 121, 'coach': 122, 'effect': 123, 'face': 124, 'trees': 125, 'same': 126, 'stood': 127, 'another': 128, 'dracula': 129, 'should': 130, 'far': 131, 'found': 132, 'made': 133, 'every': 134, 'howling': 135, 'still': 136, 'more': 137, 'day': 138, 'hills': 139, 'such': 140, 'each': 141, 'pass': 142, 'looking': 143, 'room': 144, 'many': 145, 'eyes': 146, 'only': 147, 'its': 148, 'swept': 149, 'himself': 150, 'hand': 151, 'left': 152, 'late': 153, 'little': 154, 'rather': 155, 'able': 156, 'carpathians': 157, 'without': 158, 'something': 159, 'full': 160, 'other': 161, 'heavy': 162, 'black': 163, 'once': 164, 'however': 165, 'welcome': 166, 'kept': 167, 'themselves': 168, 'off': 169, 'seat': 170, 'green': 171, 'whose': 172, 'flame': 173, 'grew': 174, 'calèche': 175, 'supper': 176, 'get': 177, 'asked': 178, 'bukovina': 179, 'yet': 180, 'about': 181, 'sleep': 182, 'under': 183, 'further': 184, 'kind': 185, 'ran': 186, 'evidently': 187, 'journey': 188, 'where': 189, 'put': 190, 'fear': 191, 'till': 192, 'these': 193, 'against': 194, 'passengers': 195, 'right': 196, 'upon': 197, 'myself': 198, 'bistritz': 199, 'morning': 200, 'near': 201, 'among': 202, 'good': 203, 'red': 204, 'called': 205, 'german': 206, 'london': 207, 'least': 208, 'shall': 209, 'going': 210, 'excellent': 211, 'sometimes': 212, 'wide': 213, 'people': 214, 'home': 215, 'coming': 216, 'expected': 217, 'too': 218, 'herr': 219, 'things': 220, 'two': 221, 'rose': 222, 'passed': 223, 'awake': 224, 'word': 225, 'amongst': 226, 'crossing': 227, 'speaking': 228, 'opened': 229, 'fell': 230, 'grim': 231, 'lamps': 232, 'appeared': 233, 'take': 234, 'turned': 235, 'heard': 236, 'strength': 237, 'felt': 238, 'suddenly': 239, 'around': 240, 'east': 241, 'done': 242, 'mem': 243, 'mina': 244, 'how': 245, 'find': 246, 'mountains': 247, 'known': 248, 'castle': 249, 'enter': 250, 'window': 251, 'towards': 252, 'call': 253, 'started': 254, 'carriage': 255, 'strong': 256, 'picturesque': 257, 'big': 258, 'rest': 259, 'hair': 260, 'told': 261, 'borgo': 262, 'has': 263, 'lost': 264, 'close': 265, 'letter': 266, 'friend': 267, 'bring': 268, 'land': 269, 'understand': 270, 'knew': 271, 'both': 272, 'saying': 273, 'state': 274, 'english': 275, 'suppose': 276, 'feeling': 277, 'sun': 278, 'jagged': 279, 'fire': 280, 'hear': 281, 'sign': 282, 'meant': 283, 'pine': 284, 'blue': 285, 'companions': 286, 'behind': 287, 'held': 288, 'noticed': 289, 'even': 290, 'ears': 291, 'gloom': 292, 'clouds': 293, 'wind': 294, 'smile': 295, 'forward': 296, 'teeth': 297, 'within': 298, 'sound': 299, 'stone': 300, 'jonathan': 301, 'next': 302, 'train': 303, 'hour': 304, 'seems': 305, 'walk': 306, 'station': 307, 'leaving': 308, 'most': 309, 'hotel': 310, 'paprika': 311, 'dish': 312, 'maps': 313, 'transylvania': 314, 'three': 315, 'four': 316, 'mixed': 317, 'read': 318, 'world': 319, 'centre': 320, 'stay': 321, 'ask': 322, 'queer': 323, 'dog': 324, 'water': 325, 'top': 326, 'steep': 327, 'lot': 328, 'outside': 329, 'peasants': 330, 'trousers': 331, 'course': 332, 'figures': 333, 'slovaks': 334, 'nails': 335, 'high': 336, 'set': 337, 'being': 338, 'certainly': 339, 'almost': 340, 'gave': 341, 'morrow': 342, 'trust': 343, 'beautiful': 344, 'making': 345, 'answered': 346, 'questions': 347, 'lady': 348, 'sent': 349, 'crossed': 350, 'nothing': 351, 'starting': 352, 'shook': 353, 'head': 354, 'midnight': 355, 'evil': 356, 'comfort': 357, 'knees': 358, 'crucifix': 359, 'neck': 360, 'offered': 361, 'meaning': 362, 'whilst': 363, 'ghostly': 364, 'let': 365, 'dined': 366, 'taken': 367, 'words': 368, 'crowd': 369, 'say': 370, 'either': 371, 'pointed': 372, 'fingers': 373, 'passenger': 374, 'first': 375, 'unknown': 376, 'touched': 377, 'last': 378, 'covered': 379, 'whip': 380, 'soon': 381, 'fears': 382, 'drove': 383, 'woods': 384, 'end': 385, 'haste': 386, 'general': 387, 'think': 388, 'really': 389, 'point': 390, 'mighty': 391, 'lofty': 392, 'falling': 393, 'shadows': 394, 'rock': 395, 'endless': 396, 'gleam': 397, 'snow': 398, 'mountain': 399, 'evening': 400, 'fact': 401, 'peculiarly': 402, 'carried': 403, 'added': 404, 'make': 405, 'excitement': 406, 'nearer': 407, 'give': 408, 'moment': 409, 'hard': 410, 'drew': 411, 'already': 412, 'watch': 413, 'tall': 414, 'much': 415, 'sharp': 416, 'away': 417, 'luggage': 418, 'handed': 419, 'reins': 420, 'chill': 421, 'ground': 422, 'few': 423, 'howl': 424, 'became': 425, 'roadway': 426, 'fine': 427, 'disappeared': 428, 'during': 429, 'moon': 430, 'ring': 431, 'jumped': 432, 'showed': 433, 'massive': 434, 'lamp': 435, 'house': 436, 'passage': 437, 'bedroom': 438, 'ready': 439, 'chapter': 440, \"harker's\": 441, 'journal': 442, 'early': 443, 'arrived': 444, 'glimpse': 445, 'feared': 446, 'start': 447, 'possible': 448, 'west': 449, 'entering': 450, 'splendid': 451, 'traditions': 452, 'pretty': 453, 'stopped': 454, 'dinner': 455, 'chicken': 456, 'pepper': 457, 'thirsty': 458, 'recipe': 459, 'anywhere': 460, 'indeed': 461, 'having': 462, 'struck': 463, 'hardly': 464, 'named': 465, 'refresh': 466, 'nationalities': 467, 'magyars': 468, 'latter': 469, 'descended': 470, 'huns': 471, 'century': 472, 'superstition': 473, 'interesting': 474, 'comfortable': 475, 'enough': 476, 'sorts': 477, 'breakfast': 478, 'also': 479, 'hurry': 480, 'ought': 481, 'move': 482, 'beauty': 483, 'edge': 484, 'attire': 485, 'hats': 486, 'others': 487, 'sleeves': 488, 'belts': 489, 'linen': 490, 'leather': 491, 'nearly': 492, 'foot': 493, 'studded': 494, 'look': 495, 'self': 496, 'twilight': 497, 'stormy': 498, 'years': 499, 'terrible': 500, 'war': 501, 'golden': 502, 'ways': 503, 'elderly': 504, 'woman': 505, 'usual': 506, 'peasant': 507, 'front': 508, 'coloured': 509, 'bowed': 510, 'yes': 511, 'harker': 512, 'smiled': 513, 'happy': 514, 'best': 515, 'true': 516, 'exactly': 517, 'wife': 518, 'frightened': 519, 'tell': 520, 'anything': 521, 'simply': 522, 'speak': 523, 'else': 524, 'oh': 525, 'young': 526, 'grip': 527, 'language': 528, 'business': 529, 'evident': 530, 'tried': 531, 'wait': 532, 'gravely': 533, 'mind': 534, 'part': 535, 'whether': 536, 'itself': 537, 'ever': 538, 'comes': 539, '5': 540, 'grey': 541, 'odd': 542, 'lest': 543, 'simple': 544, 'glasses': 545, 'talking': 546, 'listened': 547, 'repeated': 548, 'quietly': 549, 'inn': 550, 'considerable': 551, 'size': 552, 'cross': 553, 'fellow': 554, 'guard': 555, 'eye': 556, 'meet': 557, 'yard': 558, 'background': 559, 'cracked': 560, 'small': 561, 'sight': 562, 'lay': 563, 'plum': 564, 'grass': 565, 'fallen': 566, 'mittel': 567, 'losing': 568, 'tongues': 569, 'fly': 570, 'reaching': 571, 'order': 572, 'run': 573, 'always': 574, 'afternoon': 575, 'range': 576, 'deep': 577, 'peaks': 578, 'brown': 579, 'distance': 580, 'snowy': 581, 'arm': 582, 'wound': 583, 'sank': 584, 'lower': 585, 'sunset': 586, 'delicate': 587, 'cszeks': 588, 'turn': 589, 'masses': 590, 'silver': 591, 'sure': 592, 'seated': 593, 'quite': 594, 'carrying': 595, 'cold': 596, 'growing': 597, 'valleys': 598, 'between': 599, 'lying': 600, 'cut': 601, 'closing': 602, 'threw': 603, 'seem': 604, \"driver's\": 605, 'wished': 606, 'dogs': 607, 'matters': 608, 'wild': 609, 'hold': 610, 'several': 611, 'seen': 612, 'leaned': 613, 'rolling': 614, 'air': 615, 'flickering': 616, 'rays': 617, 'steam': 618, 'driven': 619, 'cloud': 620, 'tone': 621, 'thought': 622, 'less': 623, 'turning': 624, 'worse': 625, 'snort': 626, 'beside': 627, 'lamplight': 628, 'replied': 629, 'cannot': 630, 'spoke': 631, 'mouth': 632, 'lips': 633, 'whispered': 634, 'line': 635, 'dead': 636, 'putting': 637, 'bags': 638, 'steel': 639, 'prodigious': 640, 'across': 641, 'pace': 642, 'straight': 643, 'complete': 644, 'placed': 645, 'passing': 646, 'minutes': 647, 'waited': 648, 'fright': 649, 'reared': 650, 'stand': 651, 'extraordinary': 652, 'arched': 653, 'frowning': 654, 'rocks': 655, 'colder': 656, 'afraid': 657, 'faint': 658, 'while': 659, 'asleep': 660, 'incident': 661, 'nightmare': 662, 'deceived': 663, 'clad': 664, 'silence': 665, 'can': 666, 'living': 667, 'chance': 668, 'approach': 669, 'noise': 670, 'trap': 671, 'voice': 672, 'ascending': 673, 'courtyard': 674, 'windows': 675, 'remarkable': 676, 'led': 677, 'notice': 678, 'mine': 679, 'traps': 680, 'dim': 681, 'openings': 682, 'doubts': 683, \"solicitor's\": 684, 'clerk': 685, 'solicitor': 686, 'horrible': 687, 'dawn': 688, 'drawn': 689, 'moustache': 690, 'single': 691, 'chimney': 692, 'open': 693, 'motioned': 694, 'courtly': 695, 'gesture': 696, 'freely': 697, 'stepping': 698, 'fixed': 699, 'whom': 700, 'mr': 701, 'need': 702, 'insisted': 703, 'sir': 704, 'lit': 705, 'table': 706, 'logs': 707, 'closed': 708, 'octagonal': 709, 'toilet': 710, \"count's\": 711, 'courteous': 712, 'fireplace': 713, 'sup': 714, 'silent': 715, 'smoke': 716, 'thin': 717, 'nose': 718, 'broad': 719, 'hands': 720, 'seeing': 721, '3': 722, 'munich': 723, '8': 724, '35': 725, 'p': 726, 'm': 727, '1st': 728, 'arriving': 729, 'vienna': 730, '6': 731, '46': 732, 'buda': 733, 'pesth': 734, 'wonderful': 735, 'streets': 736, 'correct': 737, 'impression': 738, 'western': 739, 'bridges': 740, 'danube': 741, 'noble': 742, 'width': 743, 'depth': 744, 'turkish': 745, 'rule': 746, 'nightfall': 747, 'klausenburgh': 748, 'royale': 749, 'waiter': 750, 'hendl': 751, 'national': 752, 'smattering': 753, 'useful': 754, \"don't\": 755, 'disposal': 756, 'visited': 757, 'british': 758, 'museum': 759, 'search': 760, 'books': 761, 'library': 762, 'regarding': 763, 'foreknowledge': 764, 'fail': 765, 'importance': 766, 'dealing': 767, 'nobleman': 768, 'district': 769, 'extreme': 770, 'borders': 771, 'states': 772, 'moldavia': 773, 'midst': 774, 'carpathian': 775, 'wildest': 776, 'portions': 777, 'europe': 778, 'map': 779, 'work': 780, 'giving': 781, 'exact': 782, 'locality': 783, 'compare': 784, 'ordnance': 785, 'survey': 786, 'post': 787, 'town': 788, 'fairly': 789, 'notes': 790, 'memory': 791, 'talk': 792, 'travels': 793, 'population': 794, 'distinct': 795, 'saxons': 796, 'south': 797, 'wallachs': 798, 'descendants': 799, 'dacians': 800, 'szekelys': 801, 'north': 802, 'claim': 803, 'attila': 804, 'conquered': 805, 'eleventh': 806, 'settled': 807, 'gathered': 808, 'horseshoe': 809, 'imaginative': 810, 'whirlpool': 811, 'bed': 812, 'dreams': 813, 'drink': 814, 'carafe': 815, 'slept': 816, 'wakened': 817, 'continuous': 818, 'knocking': 819, 'guess': 820, 'sleeping': 821, 'soundly': 822, 'porridge': 823, 'maize': 824, 'flour': 825, 'mamaliga': 826, 'egg': 827, 'plant': 828, 'stuffed': 829, 'forcemeat': 830, 'impletata': 831, 'eight': 832, 'rushing': 833, '7': 834, '30': 835, 'sit': 836, 'unpunctual': 837, 'trains': 838, 'china': 839, 'dawdle': 840, 'towns': 841, 'castles': 842, 'missals': 843, 'rivers': 844, 'streams': 845, 'stony': 846, 'margin': 847, 'subject': 848, 'floods': 849, 'takes': 850, 'running': 851, 'sweep': 852, 'river': 853, 'clear': 854, 'groups': 855, 'crowds': 856, 'those': 857, 'france': 858, 'germany': 859, 'short': 860, 'jackets': 861, 'women': 862, 'except': 863, 'clumsy': 864, 'waist': 865, 'strips': 866, 'fluttering': 867, 'dresses': 868, 'ballet': 869, 'petticoats': 870, 'strangest': 871, 'barbarian': 872, 'cow': 873, 'boy': 874, 'baggy': 875, 'dirty': 876, 'shirts': 877, 'enormous': 878, 'brass': 879, 'wore': 880, 'boots': 881, 'tucked': 882, 'moustaches': 883, 'prepossessing': 884, 'stage': 885, 'oriental': 886, 'band': 887, 'brigands': 888, 'harmless': 889, 'wanting': 890, 'natural': 891, 'assertion': 892, 'practically': 893, 'frontier': 894, 'leads': 895, 'existence': 896, 'shows': 897, 'marks': 898, 'fifty': 899, 'ago': 900, 'series': 901, 'fires': 902, 'havoc': 903, 'five': 904, 'separate': 905, 'occasions': 906, 'beginning': 907, 'seventeenth': 908, 'underwent': 909, 'siege': 910, 'weeks': 911, '13': 912, '000': 913, 'casualties': 914, 'proper': 915, 'assisted': 916, 'famine': 917, 'disease': 918, 'directed': 919, 'krone': 920, 'delight': 921, 'thoroughly': 922, 'fashioned': 923, 'wanted': 924, 'faced': 925, 'cheery': 926, 'dress': 927, 'undergarment': 928, 'double': 929, 'apron': 930, 'stuff': 931, 'fitting': 932, 'tight': 933, 'modesty': 934, 'englishman': 935, 'message': 936, 'shirt': 937, 'followed': 938, 'immediately': 939, 'returned': 940, 'anxiously': 941, 'expecting': 942, 'diligence': 943, 'await': 944, 'enjoy': 945, '4': 946, 'landlord': 947, 'directing': 948, 'secure': 949, 'inquiries': 950, 'details': 951, 'somewhat': 952, 'reticent': 953, 'pretended': 954, 'because': 955, 'understood': 956, 'perfectly': 957, 'received': 958, 'mumbled': 959, 'money': 960, 'refused': 961, 'mysterious': 962, 'means': 963, 'comforting': 964, 'hysterical': 965, 'excited': 966, 'follow': 967, 'asking': 968, 'engaged': 969, 'important': 970, 'fourth': 971, 'eve': 972, 'st': 973, \"george's\": 974, 'clock': 975, 'strikes': 976, 'sway': 977, 'distress': 978, 'finally': 979, 'implored': 980, 'ridiculous': 981, 'feel': 982, 'allow': 983, 'interfere': 984, 'therefore': 985, 'raise': 986, 'thanked': 987, 'duty': 988, 'imperative': 989, 'dried': 990, 'taking': 991, 'churchman': 992, 'taught': 993, 'regard': 994, 'measure': 995, 'idolatrous': 996, 'ungracious': 997, 'refuse': 998, 'doubt': 999, 'rosary': 1000, \"mother's\": 1001, 'sake': 1002, 'writing': 1003, 'diary': 1004, 'waiting': 1005, \"lady's\": 1006, 'easy': 1007, 'book': 1008, 'reach': 1009, 'bye': 1010, 'distant': 1011, 'horizon': 1012, 'sleepy': 1013, 'naturally': 1014, 'write': 1015, 'reads': 1016, 'fancy': 1017, 'robber': 1018, 'steak': 1019, 'bits': 1020, 'bacon': 1021, 'onion': 1022, 'beef': 1023, 'seasoned': 1024, 'strung': 1025, 'sticks': 1026, 'roasted': 1027, 'style': 1028, \"cat's\": 1029, 'meat': 1030, 'wine': 1031, 'mediasch': 1032, 'produces': 1033, 'sting': 1034, 'tongue': 1035, 'disagreeable': 1036, 'couple': 1037, 'landlady': 1038, 'sitting': 1039, 'bench': 1040, 'name': 1041, 'bearer': 1042, 'pityingly': 1043, 'often': 1044, 'polyglot': 1045, 'dictionary': 1046, 'bag': 1047, 'cheering': 1048, 'ordog': 1049, 'satan': 1050, 'pokol': 1051, 'hell': 1052, 'stregoica': 1053, 'witch': 1054, 'vrolok': 1055, 'vlkoslak': 1056, 'mean': 1057, 'thing': 1058, 'slovak': 1059, 'servian': 1060, 'wolf': 1061, 'vampire': 1062, 'superstitions': 1063, 'swelled': 1064, 'difficulty': 1065, 'answer': 1066, 'learning': 1067, 'explained': 1068, 'charm': 1069, 'pleasant': 1070, 'hearted': 1071, 'sorrowful': 1072, 'sympathetic': 1073, 'never': 1074, 'forget': 1075, 'archway': 1076, 'rich': 1077, 'foliage': 1078, 'oleander': 1079, 'orange': 1080, 'tubs': 1081, 'clustered': 1082, 'drawers': 1083, 'whole': 1084, 'box': 1085, 'gotza': 1086, 'abreast': 1087, 'recollection': 1088, 'scene': 1089, 'although': 1090, 'languages': 1091, 'might': 1092, 'throw': 1093, 'easily': 1094, 'sloping': 1095, 'forests': 1096, 'crowned': 1097, 'clumps': 1098, 'farmhouses': 1099, 'blank': 1100, 'gable': 1101, 'everywhere': 1102, 'bewildering': 1103, 'mass': 1104, 'fruit': 1105, 'blossom': 1106, 'apple': 1107, 'pear': 1108, 'cherry': 1109, 'spangled': 1110, 'petals': 1111, 'grassy': 1112, 'curve': 1113, 'shut': 1114, 'straggling': 1115, 'ends': 1116, 'hillsides': 1117, 'rugged': 1118, 'feverish': 1119, 'bent': 1120, 'prund': 1121, 'summertime': 1122, 'winter': 1123, 'snows': 1124, 'respect': 1125, 'different': 1126, 'roads': 1127, 'tradition': 1128, 'hospadars': 1129, 'repair': 1130, 'turk': 1131, 'preparing': 1132, 'foreign': 1133, 'troops': 1134, 'hasten': 1135, 'loading': 1136, 'beyond': 1137, 'swelling': 1138, 'slopes': 1139, 'forest': 1140, 'steeps': 1141, 'towered': 1142, 'bringing': 1143, 'glorious': 1144, 'colours': 1145, 'purple': 1146, 'mingled': 1147, 'perspective': 1148, 'crags': 1149, 'grandly': 1150, 'rifts': 1151, 'sink': 1152, 'base': 1153, 'hill': 1154, 'peak': 1155, 'serpentine': 1156, 'isten': 1157, 'szek': 1158, \"god's\": 1159, 'reverently': 1160, 'creep': 1161, 'emphasised': 1162, 'glow': 1163, 'cool': 1164, 'pink': 1165, 'goitre': 1166, 'painfully': 1167, 'prevalent': 1168, 'roadside': 1169, 'crosses': 1170, 'kneeling': 1171, 'shrine': 1172, 'approached': 1173, 'surrender': 1174, 'devotion': 1175, 'neither': 1176, 'nor': 1177, 'outer': 1178, 'new': 1179, 'instance': 1180, 'hay': 1181, 'ricks': 1182, 'weeping': 1183, 'birch': 1184, 'stems': 1185, 'shining': 1186, 'leaves': 1187, 'leiter': 1188, 'wagon': 1189, 'ordinary': 1190, \"peasant's\": 1191, 'cart': 1192, 'snake': 1193, 'vertebra': 1194, 'calculated': 1195, 'suit': 1196, 'inequalities': 1197, 'group': 1198, 'sheepskins': 1199, 'lance': 1200, 'fashion': 1201, 'staves': 1202, 'axe': 1203, 'merge': 1204, 'mistiness': 1205, 'oak': 1206, 'beech': 1207, 'spurs': 1208, 'ascended': 1209, 'firs': 1210, 'greyness': 1211, 'bestrewed': 1212, 'produced': 1213, 'weird': 1214, 'solemn': 1215, 'thoughts': 1216, 'fancies': 1217, 'engendered': 1218, 'earlier': 1219, 'relief': 1220, 'ghost': 1221, 'ceaselessly': 1222, 'despite': 1223, 'slowly': 1224, 'fierce': 1225, 'pleasantry': 1226, 'catch': 1227, 'approving': 1228, 'stop': 1229, \"moment's\": 1230, 'pause': 1231, 'urging': 1232, 'speed': 1233, 'lashed': 1234, 'unmercifully': 1235, 'cries': 1236, 'encouragement': 1237, 'urged': 1238, 'exertions': 1239, 'patch': 1240, 'ahead': 1241, 'cleft': 1242, 'greater': 1243, 'crazy': 1244, 'rocked': 1245, 'springs': 1246, 'swayed': 1247, 'boat': 1248, 'tossed': 1249, 'sea': 1250, 'level': 1251, 'frown': 1252, 'gifts': 1253, 'pressed': 1254, 'earnestness': 1255, 'denial': 1256, 'varied': 1257, 'given': 1258, 'faith': 1259, 'kindly': 1260, 'blessing': 1261, 'mixture': 1262, 'movements': 1263, 'flew': 1264, 'craning': 1265, 'peered': 1266, 'eagerly': 1267, 'exciting': 1268, 'happening': 1269, 'slightest': 1270, 'explanation': 1271, 'opening': 1272, 'eastern': 1273, 'overhead': 1274, 'oppressive': 1275, 'sense': 1276, 'thunder': 1277, 'separated': 1278, 'atmospheres': 1279, 'thunderous': 1280, 'conveyance': 1281, 'glare': 1282, 'blackness': 1283, 'sandy': 1284, 'vehicle': 1285, 'sigh': 1286, 'gladness': 1287, 'mock': 1288, 'disappointment': 1289, 'thinking': 1290, 'spoken': 1291, 'low': 1292, 'return': 1293, 'better': 1294, 'neigh': 1295, 'plunge': 1296, 'wildly': 1297, 'chorus': 1298, 'screams': 1299, 'universal': 1300, 'overtook': 1301, 'flash': 1302, 'coal': 1303, 'animals': 1304, 'beard': 1305, 'hat': 1306, 'hide': 1307, 'pair': 1308, 'bright': 1309, 'stammered': 1310, 'reply': 1311, 'stranger': 1312, 'why': 1313, 'deceive': 1314, 'swift': 1315, 'ivory': 1316, \"burger's\": 1317, 'lenore': 1318, 'denn': 1319, 'die': 1320, 'todten': 1321, 'reiten': 1322, 'schnell': 1323, 'travel': 1324, 'fast': 1325, 'gleaming': 1326, \"herr's\": 1327, 'exceeding': 1328, 'alacrity': 1329, 'alongside': 1330, 'helping': 1331, 'caught': 1332, 'projected': 1333, 'lonely': 1334, 'cloak': 1335, 'thrown': 1336, 'shoulders': 1337, 'rug': 1338, 'mein': 1339, 'master': 1340, 'bade': 1341, 'care': 1342, 'flask': 1343, 'slivovitz': 1344, 'brandy': 1345, 'underneath': 1346, 'require': 1347, 'strangely': 1348, 'alternative': 1349, 'instead': 1350, 'prosecuting': 1351, 'note': 1352, 'salient': 1353, 'liked': 1354, 'protest': 1355, 'case': 1356, 'intention': 1357, 'delay': 1358, 'curious': 1359, 'match': 1360, 'shock': 1361, 'increased': 1362, 'recent': 1363, 'experiences': 1364, 'sick': 1365, 'suspense': 1366, 'somewhere': 1367, 'farmhouse': 1368, 'agonised': 1369, 'wailing': 1370, 'borne': 1371, 'sighed': 1372, 'softly': 1373, 'imagination': 1374, 'grasp': 1375, 'strain': 1376, 'rear': 1377, 'soothingly': 1378, 'quieted': 1379, 'shivered': 1380, 'sweated': 1381, 'runaway': 1382, 'sudden': 1383, 'louder': 1384, 'sharper': 1385, 'affected': 1386, 'minded': 1387, 'jump': 1388, 'plunged': 1389, 'madly': 1390, 'use': 1391, 'keep': 1392, 'bolting': 1393, 'accustomed': 1394, 'quiet': 1395, 'descend': 1396, 'petted': 1397, 'soothed': 1398, 'horse': 1399, 'tamers': 1400, 'doing': 1401, 'caresses': 1402, 'manageable': 1403, 'trembled': 1404, 'shaking': 1405, 'narrow': 1406, 'sharply': 1407, 'hemmed': 1408, 'places': 1409, 'tunnel': 1410, 'guarded': 1411, 'boldly': 1412, 'shelter': 1413, 'rising': 1414, 'moaned': 1415, 'whistled': 1416, 'branches': 1417, 'crashed': 1418, 'together': 1419, 'powdery': 1420, 'fall': 1421, 'blanket': 1422, 'keen': 1423, 'fainter': 1424, 'baying': 1425, 'sounded': 1426, 'dreadfully': 1427, 'shared': 1428, 'disturbed': 1429, 'checked': 1430, 'jumping': 1431, 'closer': 1432, 'wondered': 1433, 'resumed': 1434, 'dreaming': 1435, 'endlessly': 1436, 'awful': 1437, 'motions': 1438, 'rapidly': 1439, 'arose': 1440, 'illumine': 1441, 'gathering': 1442, 'stones': 1443, 'formed': 1444, 'device': 1445, 'optical': 1446, 'obstruct': 1447, 'flicker': 1448, 'startled': 1449, 'momentary': 1450, 'straining': 1451, 'flames': 1452, 'sped': 1453, 'onwards': 1454, 'following': 1455, 'moving': 1456, 'circle': 1457, 'afield': 1458, 'gone': 1459, 'absence': 1460, 'tremble': 1461, 'scream': 1462, 'cause': 1463, 'ceased': 1464, 'altogether': 1465, 'sailing': 1466, 'crest': 1467, 'beetling': 1468, 'lolling': 1469, 'sinewy': 1470, 'limbs': 1471, 'shaggy': 1472, 'hundred': 1473, 'times': 1474, 'howled': 1475, 'paralysis': 1476, 'feels': 1477, 'horrors': 1478, 'import': 1479, 'moonlight': 1480, 'peculiar': 1481, 'helplessly': 1482, 'rolled': 1483, 'painful': 1484, 'terror': 1485, 'encompassed': 1486, 'perforce': 1487, 'remain': 1488, 'coachman': 1489, 'try': 1490, 'break': 1491, 'aid': 1492, 'shouted': 1493, 'beat': 1494, 'hoping': 1495, 'scare': 1496, 'raised': 1497, 'imperious': 1498, 'command': 1499, 'arms': 1500, 'brushing': 1501, 'aside': 1502, 'impalpable': 1503, 'obstacle': 1504, 'climbing': 1505, 'uncanny': 1506, 'dreadful': 1507, 'interminable': 1508, 'obscured': 1509, 'occasional': 1510, 'periods': 1511, 'quick': 1512, 'descent': 1513, 'main': 1514, 'conscious': 1515, 'act': 1516, 'pulling': 1517, 'vast': 1518, 'ruined': 1519, 'ray': 1520, 'broken': 1521, 'battlements': 1522, 'moonlit': 1523, 'sky': 1524, 'ii': 1525, 'continued': 1526, 'fully': 1527, 'arches': 1528, 'perhaps': 1529, 'bigger': 1530, 'daylight': 1531, 'assist': 1532, 'alight': 1533, 'actually': 1534, 'vice': 1535, 'crushed': 1536, 'chosen': 1537, 'large': 1538, 'iron': 1539, 'projecting': 1540, 'doorway': 1541, 'massively': 1542, 'carved': 1543, 'carving': 1544, 'worn': 1545, 'weather': 1546, 'bell': 1547, 'knocker': 1548, 'walls': 1549, 'likely': 1550, 'penetrate': 1551, 'crowding': 1552, 'adventure': 1553, 'embarked': 1554, 'customary': 1555, 'life': 1556, 'explain': 1557, 'purchase': 1558, 'estate': 1559, 'foreigner': 1560, 'examination': 1561, 'successful': 1562, 'blown': 1563, 'rub': 1564, 'pinch': 1565, 'struggling': 1566, 'overwork': 1567, 'flesh': 1568, 'pinching': 1569, 'test': 1570, 'patient': 1571, 'conclusion': 1572, 'step': 1573, 'approaching': 1574, 'chinks': 1575, 'rattling': 1576, 'chains': 1577, 'clanking': 1578, 'bolts': 1579, 'key': 1580, 'loud': 1581, 'grating': 1582, 'disuse': 1583, 'swung': 1584, 'clean': 1585, 'shaven': 1586, 'save': 1587, 'speck': 1588, 'colour': 1589, 'antique': 1590, 'burned': 1591, 'globe': 1592, 'throwing': 1593, 'quivering': 1594, 'flickered': 1595, 'draught': 1596, 'intonation': 1597, 'motion': 1598, 'statue': 1599, 'instant': 1600, 'stepped': 1601, 'threshold': 1602, 'moved': 1603, 'impulsively': 1604, 'holding': 1605, 'grasped': 1606, 'wince': 1607, 'lessened': 1608, 'ice': 1609, 'safely': 1610, 'leave': 1611, 'happiness': 1612, 'handshake': 1613, 'akin': 1614, 'doubted': 1615, 'person': 1616, 'interrogatively': 1617, 'bid': 1618, 'eat': 1619, 'bracket': 1620, 'wall': 1621, 'forestall': 1622, 'protested': 1623, 'nay': 1624, 'guest': 1625, 'available': 1626, 'winding': 1627, 'stair': 1628, 'floor': 1629, 'steps': 1630, 'rang': 1631, 'heavily': 1632, 'rejoiced': 1633, 'spread': 1634, 'hearth': 1635, 'freshly': 1636, 'replenished': 1637, 'flamed': 1638, 'flared': 1639, 'halted': 1640, 'seemingly': 1641, 'lighted': 1642, 'warmed': 1643, 'log': 1644, 'lately': 1645, 'fresh': 1646, 'hollow': 1647, 'roar': 1648, 'inside': 1649, 'withdrew': 1650, 'yourself': 1651, 'wish': 1652, 'prepared': 1653, 'warmth': 1654, 'dissipated': 1655, 'reached': 1656, 'normal': 1657, 'discovered': 1658, 'half': 1659, 'famished': 1660, 'hunger': 1661, 'hasty': 1662, 'laid': 1663, 'host': 1664, 'leaning': 1665, 'stonework': 1666, 'graceful': 1667, 'wave': 1668, 'pray': 1669, 'please': 1670, 'excuse': 1671, 'join': 1672, 'sealed': 1673, 'hawkins': 1674, 'entrusted': 1675, 'charming': 1676, 'thrill': 1677, 'pleasure': 1678, 'regret': 1679, 'attack': 1680, 'gout': 1681, 'malady': 1682, 'constant': 1683, 'sufferer': 1684, 'forbids': 1685, 'absolutely': 1686, 'travelling': 1687, 'send': 1688, 'sufficient': 1689, 'substitute': 1690, 'confidence': 1691, 'energy': 1692, 'talent': 1693, 'faithful': 1694, 'disposition': 1695, 'discreet': 1696, 'grown': 1697, 'manhood': 1698, 'service': 1699, 'attend': 1700, 'instructions': 1701, 'cover': 1702, 'roast': 1703, 'cheese': 1704, 'salad': 1705, 'bottle': 1706, 'tokay': 1707, 'eating': 1708, 'degrees': 1709, 'experienced': 1710, 'finished': 1711, \"host's\": 1712, 'desire': 1713, 'chair': 1714, 'begun': 1715, 'cigar': 1716, 'excusing': 1717, 'opportunity': 1718, 'observing': 1719, 'marked': 1720, 'physiognomy': 1721, 'aquiline': 1722, 'bridge': 1723, 'nostrils': 1724, 'domed': 1725, 'forehead': 1726, 'scantily': 1727, 'temples': 1728, 'profusely': 1729, 'elsewhere': 1730, 'eyebrows': 1731, 'meeting': 1732, 'bushy': 1733, 'curl': 1734, 'profusion': 1735, 'cruel': 1736, 'protruded': 1737, 'ruddiness': 1738, 'astonishing': 1739, 'vitality': 1740, 'pale': 1741, 'tops': 1742, 'extremely': 1743, 'chin': 1744, 'cheeks': 1745, 'firm': 1746, 'pallor': 1747, 'hitherto': 1748, 'backs': 1749, 'firelight': 1750, 'coarse': 1751, 'squat': 1752, 'hairs': 1753, 'palm': 1754, 'repress': 1755, 'shudder': 1756, 'breath': 1757, 'rank': 1758, 'nausea': 1759, 'conceal': 1760, 'noticing': 1761, 'protuberant': 1762, 'sat': 1763, 'streak': 1764, 'stillness': 1765, 'everything': 1766, 'below': 1767, 'valley': 1768, 'gleamed': 1769, 'listen': 1770, 'children': 1771, 'music': 1772, 'expression': 1773, 'ah': 1774, 'dwellers': 1775, 'city': 1776, 'feelings': 1777, 'hunter': 1778, 'tired': 1779, 'dream': 1780, 'bow': 1781, 'entered': 1782}\n"
          ]
        }
      ],
      "source": [
        "with open ('/content/data (3).txt','r',encoding = 'utf-8') as f:\n",
        "  text = f.read()\n",
        "  from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts([text])\n",
        "  total_words = len(tokenizer.word_index)+1\n",
        "  print(total_words)\n",
        "  print(tokenizer.word_index)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence = []\n",
        "for line in text.split('\\n'):\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(1,len(token_list)):\n",
        "    n_gram_sequence = token_list[:i+1]\n",
        "    input_sequence.append(n_gram_sequence)\n",
        "input_sequence[:20]"
      ],
      "metadata": {
        "id": "UeQ074EdrtWt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1344ad4-8585-4d0a-bd43-bd8ca8133727"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[440, 4],\n",
              " [301, 441],\n",
              " [301, 441, 442],\n",
              " [722, 77],\n",
              " [722, 77, 199],\n",
              " [722, 77, 199, 152],\n",
              " [722, 77, 199, 152, 723],\n",
              " [722, 77, 199, 152, 723, 25],\n",
              " [722, 77, 199, 152, 723, 25, 724],\n",
              " [722, 77, 199, 152, 723, 25, 724, 725],\n",
              " [722, 77, 199, 152, 723, 25, 724, 725, 726],\n",
              " [722, 77, 199, 152, 723, 25, 724, 725, 726, 727],\n",
              " [722, 77, 199, 152, 723, 25, 724, 725, 726, 727, 15],\n",
              " [722, 77, 199, 152, 723, 25, 724, 725, 726, 727, 15, 728],\n",
              " [722, 77, 199, 152, 723, 25, 724, 725, 726, 727, 15, 728, 77],\n",
              " [722, 77, 199, 152, 723, 25, 724, 725, 726, 727, 15, 728, 77, 729],\n",
              " [722, 77, 199, 152, 723, 25, 724, 725, 726, 727, 15, 728, 77, 729, 25],\n",
              " [730, 443],\n",
              " [730, 443, 302],\n",
              " [730, 443, 302, 200]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(x) for x in input_sequence])\n",
        "print(max_len)\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "pad_sequence = pad_sequences(input_sequence, maxlen = max_len, padding='pre')\n",
        "pad_sequence[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPnM3Go1tYIN",
        "outputId": "12f343c6-50b8-485a-bd32-c2de24d286ae"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0, 440,   4],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0, 301, 441],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 301, 441, 442],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0, 722,  77],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 722,  77, 199],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        722,  77, 199, 152],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 722,\n",
              "         77, 199, 152, 723],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 722,  77,\n",
              "        199, 152, 723,  25],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 722,  77, 199,\n",
              "        152, 723,  25, 724],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 722,  77, 199, 152,\n",
              "        723,  25, 724, 725],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 722,  77, 199, 152, 723,\n",
              "         25, 724, 725, 726],\n",
              "       [  0,   0,   0,   0,   0,   0,   0, 722,  77, 199, 152, 723,  25,\n",
              "        724, 725, 726, 727],\n",
              "       [  0,   0,   0,   0,   0,   0, 722,  77, 199, 152, 723,  25, 724,\n",
              "        725, 726, 727,  15],\n",
              "       [  0,   0,   0,   0,   0, 722,  77, 199, 152, 723,  25, 724, 725,\n",
              "        726, 727,  15, 728],\n",
              "       [  0,   0,   0,   0, 722,  77, 199, 152, 723,  25, 724, 725, 726,\n",
              "        727,  15, 728,  77],\n",
              "       [  0,   0,   0, 722,  77, 199, 152, 723,  25, 724, 725, 726, 727,\n",
              "         15, 728,  77, 729],\n",
              "       [  0,   0, 722,  77, 199, 152, 723,  25, 724, 725, 726, 727,  15,\n",
              "        728,  77, 729,  25],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0, 730, 443],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 730, 443, 302],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        730, 443, 302, 200]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=pad_sequence[:,:-1]\n",
        "y=pad_sequence[:,-1]\n",
        "print(x.shape,y.shape)\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y=to_categorical(y,num_classes=total_words)\n",
        "print(y.shape)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvN1qVMpvI2Y",
        "outputId": "a91375f2-75dd-41f9-d434-a58b2e20a107"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7047, 16) (7047,)\n",
            "(7047, 1783)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, RNN, GRU\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100,input_length = max_len-1))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(total_words, activation = 'softmax'))\n",
        "model.build(input_shape = (None, max_len-1))\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "QZauXnkFwJCP",
        "outputId": "fc97e2e6-5134-4aae-f375-fbc10268318d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │       \u001b[38;5;34m178,300\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m150,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1783\u001b[0m)           │       \u001b[38;5;34m269,233\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">178,300</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1783</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">269,233</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m598,133\u001b[0m (2.28 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">598,133</span> (2.28 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m598,133\u001b[0m (2.28 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">598,133</span> (2.28 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss = 'categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(x,y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVrOjxoTycfe",
        "outputId": "4d4a1d41-cd28-44ae-88cb-c71d90b7c74a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.0579 - loss: 6.6209\n",
            "Epoch 2/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 0.0745 - loss: 5.8516\n",
            "Epoch 3/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - accuracy: 0.0832 - loss: 5.7199\n",
            "Epoch 4/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.0922 - loss: 5.5532\n",
            "Epoch 5/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.0932 - loss: 5.4140\n",
            "Epoch 6/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - accuracy: 0.1137 - loss: 5.1965\n",
            "Epoch 7/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - accuracy: 0.1369 - loss: 4.9822\n",
            "Epoch 8/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - accuracy: 0.1329 - loss: 4.8260\n",
            "Epoch 9/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.1519 - loss: 4.6242\n",
            "Epoch 10/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.1625 - loss: 4.4732\n",
            "Epoch 11/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.1763 - loss: 4.2869\n",
            "Epoch 12/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 46ms/step - accuracy: 0.2085 - loss: 4.0743\n",
            "Epoch 13/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 58ms/step - accuracy: 0.2112 - loss: 3.9539\n",
            "Epoch 14/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.2252 - loss: 3.8079\n",
            "Epoch 15/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.2522 - loss: 3.6097\n",
            "Epoch 16/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.2738 - loss: 3.4549\n",
            "Epoch 17/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.3150 - loss: 3.2384\n",
            "Epoch 18/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.3436 - loss: 3.0854\n",
            "Epoch 19/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.3712 - loss: 2.9592\n",
            "Epoch 20/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.4114 - loss: 2.8060\n",
            "Epoch 21/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - accuracy: 0.4192 - loss: 2.6880\n",
            "Epoch 22/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step - accuracy: 0.4732 - loss: 2.4981\n",
            "Epoch 23/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.5121 - loss: 2.3337\n",
            "Epoch 24/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 0.5309 - loss: 2.2394\n",
            "Epoch 25/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step - accuracy: 0.5628 - loss: 2.1112\n",
            "Epoch 26/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.5884 - loss: 1.9759\n",
            "Epoch 27/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.6295 - loss: 1.8194\n",
            "Epoch 28/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.6436 - loss: 1.7235\n",
            "Epoch 29/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - accuracy: 0.6756 - loss: 1.5963\n",
            "Epoch 30/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - accuracy: 0.6982 - loss: 1.5128\n",
            "Epoch 31/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.7241 - loss: 1.4164\n",
            "Epoch 32/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - accuracy: 0.7372 - loss: 1.3292\n",
            "Epoch 33/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.7560 - loss: 1.2314\n",
            "Epoch 34/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.7813 - loss: 1.1601\n",
            "Epoch 35/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.8040 - loss: 1.0691\n",
            "Epoch 36/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.8096 - loss: 1.0336\n",
            "Epoch 37/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.8233 - loss: 0.9636\n",
            "Epoch 38/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.8368 - loss: 0.8902\n",
            "Epoch 39/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.8534 - loss: 0.8426\n",
            "Epoch 40/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - accuracy: 0.8585 - loss: 0.7942\n",
            "Epoch 41/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.8746 - loss: 0.7329\n",
            "Epoch 42/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.8874 - loss: 0.6816\n",
            "Epoch 43/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 67ms/step - accuracy: 0.8938 - loss: 0.6470\n",
            "Epoch 44/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.9015 - loss: 0.5858\n",
            "Epoch 45/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.9138 - loss: 0.5453\n",
            "Epoch 46/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 42ms/step - accuracy: 0.9180 - loss: 0.5189\n",
            "Epoch 47/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step - accuracy: 0.9317 - loss: 0.4629\n",
            "Epoch 48/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.9287 - loss: 0.4459\n",
            "Epoch 49/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 68ms/step - accuracy: 0.9345 - loss: 0.4023\n",
            "Epoch 50/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 50ms/step - accuracy: 0.9364 - loss: 0.3931\n",
            "Epoch 51/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 41ms/step - accuracy: 0.9467 - loss: 0.3655\n",
            "Epoch 52/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - accuracy: 0.9455 - loss: 0.3336\n",
            "Epoch 53/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.9518 - loss: 0.3069\n",
            "Epoch 54/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.9563 - loss: 0.2892\n",
            "Epoch 55/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - accuracy: 0.9535 - loss: 0.2737\n",
            "Epoch 56/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 48ms/step - accuracy: 0.9549 - loss: 0.2574\n",
            "Epoch 57/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - accuracy: 0.9529 - loss: 0.2548\n",
            "Epoch 58/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.9623 - loss: 0.2190\n",
            "Epoch 59/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.9613 - loss: 0.2174\n",
            "Epoch 60/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9591 - loss: 0.2011\n",
            "Epoch 61/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.9645 - loss: 0.1808\n",
            "Epoch 62/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.9647 - loss: 0.1803\n",
            "Epoch 63/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.9588 - loss: 0.1758\n",
            "Epoch 64/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - accuracy: 0.9654 - loss: 0.1600\n",
            "Epoch 65/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.9621 - loss: 0.1537\n",
            "Epoch 66/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.9577 - loss: 0.1521\n",
            "Epoch 67/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.9660 - loss: 0.1399\n",
            "Epoch 68/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.9629 - loss: 0.1349\n",
            "Epoch 69/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.9637 - loss: 0.1371\n",
            "Epoch 70/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.9621 - loss: 0.1378\n",
            "Epoch 71/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.9598 - loss: 0.1264\n",
            "Epoch 72/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.9626 - loss: 0.1266\n",
            "Epoch 73/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.9634 - loss: 0.1150\n",
            "Epoch 74/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.9583 - loss: 0.1302\n",
            "Epoch 75/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.9631 - loss: 0.1156\n",
            "Epoch 76/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.9658 - loss: 0.1021\n",
            "Epoch 77/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.9588 - loss: 0.1148\n",
            "Epoch 78/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.9639 - loss: 0.1058\n",
            "Epoch 79/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.9636 - loss: 0.1082\n",
            "Epoch 80/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.9657 - loss: 0.0951\n",
            "Epoch 81/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.9640 - loss: 0.0969\n",
            "Epoch 82/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.9624 - loss: 0.1029\n",
            "Epoch 83/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - accuracy: 0.9671 - loss: 0.0923\n",
            "Epoch 84/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.9612 - loss: 0.1013\n",
            "Epoch 85/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.9617 - loss: 0.0959\n",
            "Epoch 86/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.9593 - loss: 0.0975\n",
            "Epoch 87/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.9636 - loss: 0.0983\n",
            "Epoch 88/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.9639 - loss: 0.0847\n",
            "Epoch 89/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.9619 - loss: 0.1082\n",
            "Epoch 90/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.9587 - loss: 0.1226\n",
            "Epoch 91/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.9624 - loss: 0.0962\n",
            "Epoch 92/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.9614 - loss: 0.0963\n",
            "Epoch 93/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.9618 - loss: 0.0941\n",
            "Epoch 94/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 41ms/step - accuracy: 0.9660 - loss: 0.0807\n",
            "Epoch 95/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - accuracy: 0.9660 - loss: 0.0833\n",
            "Epoch 96/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.9662 - loss: 0.0847\n",
            "Epoch 97/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.9630 - loss: 0.0889\n",
            "Epoch 98/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.9637 - loss: 0.0894\n",
            "Epoch 99/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.9665 - loss: 0.0801\n",
            "Epoch 100/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.9630 - loss: 0.0834\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78099e456150>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('nextword.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Axf8Zq_Xzdxs",
        "outputId": "d16aa412-0f7f-45a3-d06a-acb11e581715"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('nextword.h5')\n",
        "import numpy as np\n",
        "import time\n",
        "seed_text = \"I will leave if they\"\n",
        "next_words = 10\n",
        "for _ in range(next_words):\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "  token_list = pad_sequences([token_list], maxlen = max_len-1, padding = 'pre')\n",
        "  predicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "  output_word = \"\"\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted:\n",
        "      output_word = word\n",
        "      break\n",
        "  seed_text += \" \" + output_word\n",
        "print(seed_text)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dy1VHv7zds7",
        "outputId": "8e3b70e9-3adf-4ca7-eeaa-85d76578db96"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "I will leave if they call here the driver jumped down and held out his\n"
          ]
        }
      ]
    }
  ]
}